use_gpu: False
device: 0
backend: torch
outdir: vFL_adult
federate:
  mode: standalone
  client_num: 2
  total_round_num: 30
model:
  type: lr
  use_bias: False
train:
  optimizer:
    lr: 0.5
data:
  root: data/
  type: adult
  splits: [1.0, 0.0]
  args: [{normalization: False, standardization: True}]
dataloader:
  type: raw
  batch_size: 50
criterion:
  type: CrossEntropyLoss
trainer:
  type: none
vertical:
  use: True
  key_size: 256
  dims: [7, 14]
eval:
  freq: 5
  best_res_update_round_wise_key: test_loss
hpo:
  scheduler: sha
  num_workers: 0
  init_cand_num: 27
  ss: 'federatedscope/autotune/baseline/vfl_ss.yaml'
  sha:
    budgets: [12, 13, 19]
  metric: 'server_global_eval.test_loss'
  working_folder: sha_femnist_avg